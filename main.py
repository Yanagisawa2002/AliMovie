#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸºäºTransformerçš„å†·å¯åŠ¨æ¨èç³»ç»Ÿ
å‚è€ƒé˜¿é‡ŒGPSDæ¡†æ¶ï¼šç”Ÿæˆå¼é¢„è®­ç»ƒ + å¾®è°ƒ

ä¸»è¦åŠŸèƒ½ï¼š
1. MovieLens-1Mæ•°æ®é¢„å¤„ç†
2. ä¸¤é˜¶æ®µè®­ç»ƒï¼ˆé¢„è®­ç»ƒ + å¾®è°ƒï¼‰
3. å†·å¯åŠ¨ç”¨æˆ·æ¨èè¯„ä¼°
4. A/Bæµ‹è¯•GMVæ¨¡æ‹Ÿ
"""

import os
import torch
import argparse
import json
import time
from datetime import datetime
from typing import Dict, Any

from data_preprocessing import MovieLensDataProcessor, create_dataloaders
from model import GPSDRecommender
from trainer import RecommenderTrainer, create_trainer_from_config
from evaluator import RecommendationEvaluator, print_evaluation_report

def setup_directories():
    """åˆ›å»ºå¿…è¦çš„ç›®å½•ç»“æ„"""
    directories = [
        './data',
        './models',
        './results',
        './logs'
    ]
    
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
        print(f"âœ“ åˆ›å»ºç›®å½•: {directory}")

def save_config(config: Dict[str, Any], save_path: str):
    """ä¿å­˜é…ç½®æ–‡ä»¶"""
    with open(save_path, 'w', encoding='utf-8') as f:
        json.dump(config, f, indent=2, ensure_ascii=False)
    print(f"âœ“ é…ç½®å·²ä¿å­˜åˆ°: {save_path}")

def load_config(config_path: str) -> Dict[str, Any]:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    with open(config_path, 'r', encoding='utf-8') as f:
        config = json.load(f)
    print(f"âœ“ é…ç½®å·²ä» {config_path} åŠ è½½")
    return config

def main():
    parser = argparse.ArgumentParser(description='åŸºäºTransformerçš„å†·å¯åŠ¨æ¨èç³»ç»Ÿ')
    
    # åŸºæœ¬å‚æ•°
    parser.add_argument('--mode', type=str, choices=['train', 'evaluate', 'full'], 
                       default='full', help='è¿è¡Œæ¨¡å¼')
    parser.add_argument('--config', type=str, default='./config.json', 
                       help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--data_path', type=str, default='./data/', 
                       help='æ•°æ®è·¯å¾„')
    parser.add_argument('--model_path', type=str, default='./models/', 
                       help='æ¨¡å‹ä¿å­˜è·¯å¾„')
    parser.add_argument('--results_path', type=str, default='./results/', 
                       help='ç»“æœä¿å­˜è·¯å¾„')
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--d_model', type=int, default=256, help='æ¨¡å‹ç»´åº¦')
    parser.add_argument('--n_heads', type=int, default=8, help='æ³¨æ„åŠ›å¤´æ•°')
    parser.add_argument('--n_layers', type=int, default=6, help='Transformerå±‚æ•°')
    parser.add_argument('--d_ff', type=int, default=1024, help='å‰é¦ˆç½‘ç»œç»´åº¦')
    parser.add_argument('--max_seq_len', type=int, default=50, help='æœ€å¤§åºåˆ—é•¿åº¦')
    parser.add_argument('--dropout', type=float, default=0.1, help='Dropoutç‡')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--pretrain_epochs', type=int, default=1, help='é¢„è®­ç»ƒè½®æ•°')
    parser.add_argument('--finetune_epochs', type=int, default=2, help='å¾®è°ƒè½®æ•°')
    parser.add_argument('--batch_size', type=int, default=64, help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--learning_rate', type=float, default=1e-4, help='å­¦ä¹ ç‡')
    parser.add_argument('--weight_decay', type=float, default=1e-5, help='æƒé‡è¡°å‡')
    
    # æ•°æ®å‚æ•°
    parser.add_argument('--long_tail_threshold', type=int, default=5, 
                       help='é•¿å°¾ç”¨æˆ·äº¤äº’é˜ˆå€¼')
    parser.add_argument('--pretrain_sample_frac', type=float, default=0.1, 
                       help='é¢„è®­ç»ƒæ•°æ®é‡‡æ ·æ¯”ä¾‹')
    parser.add_argument('--train_ratio', type=float, default=0.8, 
                       help='è®­ç»ƒé›†æ¯”ä¾‹')
    
    # è®¾å¤‡å‚æ•°
    parser.add_argument('--device', type=str, default='auto', 
                       help='è®¡ç®—è®¾å¤‡ (auto/cpu/cuda)')
    parser.add_argument('--seed', type=int, default=42, help='éšæœºç§å­')
    
    args = parser.parse_args()
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(args.seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(args.seed)
    
    # è®¾ç½®è®¾å¤‡
    if args.device == 'auto':
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    else:
        device = torch.device(args.device)
    
    print(f"ğŸš€ å¯åŠ¨æ¨èç³»ç»Ÿè®­ç»ƒ")
    print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {device}")
    print(f"ğŸ¯ è¿è¡Œæ¨¡å¼: {args.mode}")
    print(f"ğŸŒ± éšæœºç§å­: {args.seed}")
    
    # åˆ›å»ºç›®å½•
    setup_directories()
    
    # ä¿å­˜é…ç½®
    config = vars(args)
    config['timestamp'] = datetime.now().isoformat()
    config['device_name'] = str(device)
    save_config(config, os.path.join(args.results_path, 'config.json'))
    
    # æ•°æ®é¢„å¤„ç†
    print("\n" + "="*50)
    print("ğŸ“Š æ•°æ®é¢„å¤„ç†é˜¶æ®µ")
    print("="*50)
    
    processor = MovieLensDataProcessor(
        data_path=args.data_path,
        max_seq_len=args.max_seq_len
    )
    
    # åŠ è½½å’Œå¤„ç†æ•°æ®
    print("ğŸ“¥ åŠ è½½MovieLensæ•°æ®...")
    ratings = processor.load_movielens_data()
    print(f"âœ“ åŸå§‹æ•°æ®é‡: {len(ratings):,} æ¡è¯„åˆ†")
    
    # ç¼–ç ç”¨æˆ·å’Œç‰©å“
    print("ğŸ”¢ ç¼–ç ç”¨æˆ·å’Œç‰©å“ID...")
    ratings = processor.encode_items_and_users(ratings)
    
    # è¯†åˆ«é•¿å°¾ç”¨æˆ·
    print(f"ğŸ¯ è¯†åˆ«é•¿å°¾ç”¨æˆ· (äº¤äº’æ¬¡æ•° < {args.long_tail_threshold})...")
    long_tail_data = processor.identify_long_tail_users(ratings, args.long_tail_threshold)
    
    # åˆ›å»ºé¢„è®­ç»ƒæ•°æ®
    print(f"ğŸ“¦ åˆ›å»ºé¢„è®­ç»ƒæ•°æ® ({args.pretrain_sample_frac*100:.1f}% é‡‡æ ·)...")
    pretrain_data = processor.create_pretrain_data(ratings, args.pretrain_sample_frac)
    
    # åˆ›å»ºåºåˆ—æ•°æ®
    print("ğŸ”„ ç”Ÿæˆåºåˆ—æ•°æ®...")
    pretrain_sequences = processor.create_sequences(pretrain_data)
    finetune_sequences = processor.create_sequences(long_tail_data)
    
    # ä¿å­˜ç¼–ç å™¨
    processor.save_encoders(args.model_path)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print("ğŸ”§ åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
    pretrain_train_loader, pretrain_val_loader = create_dataloaders(
        pretrain_sequences, args.batch_size, args.train_ratio, args.max_seq_len
    )
    
    finetune_train_loader, finetune_val_loader = create_dataloaders(
        finetune_sequences, args.batch_size, args.train_ratio, args.max_seq_len
    )
    
    print(f"âœ“ é¢„è®­ç»ƒæ•°æ®: {len(pretrain_sequences):,} åºåˆ—")
    print(f"âœ“ å¾®è°ƒæ•°æ®: {len(finetune_sequences):,} åºåˆ—")
    
    if args.mode in ['train', 'full']:
        # æ¨¡å‹è®­ç»ƒ
        print("\n" + "="*50)
        print("ğŸ¤– æ¨¡å‹è®­ç»ƒé˜¶æ®µ")
        print("="*50)
        
        # åˆ›å»ºæ¨¡å‹é…ç½®
        model_config = {
            'd_model': args.d_model,
            'n_heads': args.n_heads,
            'n_layers': args.n_layers,
            'd_ff': args.d_ff,
            'max_seq_len': args.max_seq_len,
            'dropout': args.dropout
        }
        
        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = create_trainer_from_config(
            n_items=processor.n_items,
            device=device,
            model_config=model_config
        )
        
        print(f"ğŸ—ï¸ æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in trainer.model.parameters()):,}")
        
        # é¢„è®­ç»ƒé˜¶æ®µ
        print("\nğŸ”¥ å¼€å§‹é¢„è®­ç»ƒ...")
        start_time = time.time()
        
        pretrain_history = trainer.pretrain(
            pretrain_train_loader,
            pretrain_val_loader,
            epochs=args.pretrain_epochs,
            save_path=os.path.join(args.model_path, 'pretrained_model.pth')
        )
        
        pretrain_time = time.time() - start_time
        print(f"âœ“ é¢„è®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {pretrain_time:.2f}ç§’")
        
        # å¾®è°ƒé˜¶æ®µ
        if finetune_train_loader is not None and finetune_val_loader is not None:
            print("\nğŸ¯ å¼€å§‹å¾®è°ƒ...")
            start_time = time.time()
            
            finetune_history = trainer.finetune(
                finetune_train_loader,
                finetune_val_loader,
                epochs=args.finetune_epochs,
                save_path=os.path.join(args.model_path, 'finetuned_model.pth'),
                early_stopping_patience=3
            )
            
            finetune_time = time.time() - start_time
            print(f"âœ“ å¾®è°ƒå®Œæˆï¼Œè€—æ—¶: {finetune_time:.2f}ç§’")
        else:
            print("\nâš ï¸ è·³è¿‡å¾®è°ƒé˜¶æ®µï¼šé•¿å°¾ç”¨æˆ·æ•°æ®ä¸ºç©º")
            finetune_history = {'train_loss': [], 'val_loss': []}
            finetune_time = 0
        
        # ç»˜åˆ¶è®­ç»ƒå†å²
        trainer.plot_training_history(
            os.path.join(args.results_path, 'training_history.png')
        )
        
        # ä¿å­˜è®­ç»ƒå†å²
        training_history = {
            'pretrain': pretrain_history,
            'finetune': finetune_history,
            'pretrain_time': pretrain_time,
            'finetune_time': finetune_time
        }
        
        with open(os.path.join(args.results_path, 'training_history.json'), 'w') as f:
            json.dump(training_history, f, indent=2)
    
    if args.mode in ['evaluate', 'full']:
        # æ¨¡å‹è¯„ä¼°
        print("\n" + "="*50)
        print("ğŸ“ˆ æ¨¡å‹è¯„ä¼°é˜¶æ®µ")
        print("="*50)
        
        # åŠ è½½æœ€ä½³æ¨¡å‹
        model_path = os.path.join(args.model_path, 'finetuned_model.pth')
        if not os.path.exists(model_path):
            model_path = os.path.join(args.model_path, 'pretrained_model.pth')
        
        if os.path.exists(model_path):
            # åˆ›å»ºè¯„ä¼°å™¨ - ä½¿ç”¨ä¸è®­ç»ƒæ—¶ç›¸åŒçš„æ¨¡å‹é…ç½®
            model_config = {
                'd_model': args.d_model,
                'n_heads': args.n_heads,
                'n_layers': args.n_layers,
                'd_ff': args.d_ff,
                'max_seq_len': args.max_seq_len,
                'dropout': args.dropout
            }
            model = GPSDRecommender(
                n_items=processor.n_items,
                d_model=args.d_model,
                n_heads=args.n_heads,
                n_layers=args.n_layers,
                d_ff=args.d_ff,
                max_seq_len=args.max_seq_len,
                dropout=args.dropout
            )
            model.load_pretrained(model_path)
            evaluator = RecommendationEvaluator(model, device)
            
            print(f"ğŸ“¥ åŠ è½½æ¨¡å‹: {model_path}")
            
            # åˆ›å»ºæµ‹è¯•æ•°æ®ï¼ˆä½¿ç”¨é•¿å°¾ç”¨æˆ·æ•°æ®çš„ä¸€éƒ¨åˆ†ï¼‰
            test_sequences = finetune_sequences[-len(finetune_sequences)//4:]  # ä½¿ç”¨25%ä½œä¸ºæµ‹è¯•é›†
            
            print(f"ğŸ§ª æµ‹è¯•åºåˆ—æ•°é‡: {len(test_sequences):,}")
            
            # è¯„ä¼°æ¨¡å‹
            print("ğŸ” å¼€å§‹æ¨¡å‹è¯„ä¼°...")
            start_time = time.time()
            
            results = evaluator.evaluate_model(
                test_sequences,
                k_values=[5, 10, 20],
                batch_size=args.batch_size
            )
            
            evaluation_time = time.time() - start_time
            print(f"âœ“ è¯„ä¼°å®Œæˆï¼Œè€—æ—¶: {evaluation_time:.2f}ç§’")
            
            # A/Bæµ‹è¯•æ¨¡æ‹Ÿ
            print("ğŸ’° æ¨¡æ‹ŸA/Bæµ‹è¯•GMVæå‡...")
            ab_test_results = evaluator.simulate_ab_test(
                test_sequences,
                baseline_gmv=1000000.0,  # 100ä¸‡åŸºå‡†GMV
                expected_improvement=7.97
            )
            
            # æ‰“å°è¯„ä¼°æŠ¥å‘Š
            print_evaluation_report(results, ab_test_results)
            
            # ç»˜åˆ¶è¯„ä¼°ç»“æœ
            evaluator.plot_evaluation_results(
                results,
                os.path.join(args.results_path, 'evaluation_results.png')
            )
            
            # ä¿å­˜è¯„ä¼°ç»“æœ
            evaluation_results = {
                'metrics': results,
                'ab_test': ab_test_results,
                'evaluation_time': evaluation_time,
                'test_sequences_count': len(test_sequences)
            }
            
            with open(os.path.join(args.results_path, 'evaluation_results.json'), 'w') as f:
                json.dump(evaluation_results, f, indent=2)
            
            print(f"ğŸ’¾ è¯„ä¼°ç»“æœå·²ä¿å­˜åˆ°: {args.results_path}")
        
        else:
            print("âŒ æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œè¯·å…ˆè¿è¡Œè®­ç»ƒæ¨¡å¼")
    
    # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    print("\n" + "="*50)
    print("ğŸ“‹ ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š")
    print("="*50)
    
    report_lines = [
        "# åŸºäºTransformerçš„å†·å¯åŠ¨æ¨èç³»ç»Ÿ - å®éªŒæŠ¥å‘Š\n",
        f"**å®éªŒæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        f"**è®¾å¤‡**: {device}\n",
        f"**æ¨¡å¼**: {args.mode}\n\n",
        "## æ•°æ®ç»Ÿè®¡\n",
        f"- åŸå§‹æ•°æ®é‡: {len(ratings):,} æ¡è¯„åˆ†\n",
        f"- ç”¨æˆ·æ•°é‡: {processor.n_users:,}\n",
        f"- ç‰©å“æ•°é‡: {processor.n_items:,}\n",
        f"- é•¿å°¾ç”¨æˆ·æ•°é‡: {len(long_tail_data['user_encoded'].unique()):,}\n",
        f"- é¢„è®­ç»ƒåºåˆ—: {len(pretrain_sequences):,}\n",
        f"- å¾®è°ƒåºåˆ—: {len(finetune_sequences):,}\n\n",
        "## æ¨¡å‹é…ç½®\n",
        f"- æ¨¡å‹ç»´åº¦: {args.d_model}\n",
        f"- æ³¨æ„åŠ›å¤´æ•°: {args.n_heads}\n",
        f"- Transformerå±‚æ•°: {args.n_layers}\n",
        f"- æœ€å¤§åºåˆ—é•¿åº¦: {args.max_seq_len}\n\n",
        "## è®­ç»ƒé…ç½®\n",
        f"- é¢„è®­ç»ƒè½®æ•°: {args.pretrain_epochs}\n",
        f"- å¾®è°ƒè½®æ•°: {args.finetune_epochs}\n",
        f"- æ‰¹æ¬¡å¤§å°: {args.batch_size}\n",
        f"- å­¦ä¹ ç‡: {args.learning_rate}\n\n"
    ]
    
    # å¦‚æœæœ‰è¯„ä¼°ç»“æœï¼Œæ·»åŠ åˆ°æŠ¥å‘Šä¸­
    if args.mode in ['evaluate', 'full'] and 'results' in locals():
        report_lines.extend([
            "## è¯„ä¼°ç»“æœ\n",
            f"- Recall@10: {results.get('Recall@10', 0):.4f}\n",
            f"- NDCG@10: {results.get('NDCG@10', 0):.4f}\n",
            f"- Precision@10: {results.get('Precision@10', 0):.4f}\n",
            f"- Coverage@10: {results.get('Coverage@10', 0):.4f}\n\n",
            "## A/Bæµ‹è¯•æ¨¡æ‹Ÿ\n",
            f"- é¢„æœŸGMVæå‡: {ab_test_results.get('gmv_improvement_%', 0):.2f}%\n",
            f"- æ–°GMV: ${ab_test_results.get('new_gmv', 0):,.2f}\n\n"
        ])
    
    report_lines.append("---\nå®éªŒå®Œæˆ âœ…")
    
    # ä¿å­˜æŠ¥å‘Š
    report_path = os.path.join(args.results_path, 'experiment_report.md')
    with open(report_path, 'w', encoding='utf-8') as f:
        f.writelines(report_lines)
    
    print(f"ğŸ“„ å®éªŒæŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
    print("\nğŸ‰ å®éªŒå®Œæˆï¼")

if __name__ == "__main__":
    main()