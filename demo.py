#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿæ¼”ç¤ºè„šæœ¬
åŸºäºTransformerçš„å†·å¯åŠ¨æ¨èç³»ç»Ÿæ¼”ç¤º

ä½¿ç”¨æ–¹æ³•:
python demo.py
"""

import torch
import numpy as np
import time
from typing import List, Dict

from data_preprocessing import MovieLensDataProcessor, create_dataloaders
from model import GPSDRecommender
from trainer import RecommenderTrainer
from evaluator import RecommendationEvaluator, print_evaluation_report

def create_demo_data(n_users: int = 1000, n_items: int = 500, n_interactions: int = 10000):
    """åˆ›å»ºæ¼”ç¤ºæ•°æ®"""
    print("ğŸ¬ åˆ›å»ºæ¼”ç¤ºæ•°æ®...")
    
    np.random.seed(42)
    
    # ç”Ÿæˆç”¨æˆ·-ç‰©å“äº¤äº’æ•°æ®
    user_ids = np.random.randint(1, n_users + 1, n_interactions)
    item_ids = np.random.randint(1, n_items + 1, n_interactions)
    ratings = np.random.choice([3, 4, 5], n_interactions, p=[0.3, 0.4, 0.3])
    timestamps = np.random.randint(1000000000, 1600000000, n_interactions)
    
    # åˆ›å»ºDataFrame
    import pandas as pd
    data = pd.DataFrame({
        'user_id': user_ids,
        'item_id': item_ids,
        'rating': ratings,
        'timestamp': timestamps
    })
    
    # å»é‡å¹¶æ’åº
    data = data.drop_duplicates(subset=['user_id', 'item_id'])
    data = data.sort_values(['user_id', 'timestamp'])
    
    print(f"âœ“ ç”Ÿæˆ {len(data):,} æ¡äº¤äº’è®°å½•")
    print(f"âœ“ ç”¨æˆ·æ•°: {data['user_id'].nunique():,}")
    print(f"âœ“ ç‰©å“æ•°: {data['item_id'].nunique():,}")
    
    return data

def demo_data_preprocessing():
    """æ¼”ç¤ºæ•°æ®é¢„å¤„ç†"""
    print("\n" + "="*50)
    print("ğŸ“Š æ•°æ®é¢„å¤„ç†æ¼”ç¤º")
    print("="*50)
    
    # åˆ›å»ºå¤„ç†å™¨
    processor = MovieLensDataProcessor(max_seq_len=20)
    
    # åˆ›å»ºæ¼”ç¤ºæ•°æ®
    ratings = create_demo_data()
    
    # ç¼–ç ç”¨æˆ·å’Œç‰©å“
    print("\nğŸ”¢ ç¼–ç ç”¨æˆ·å’Œç‰©å“ID...")
    ratings = processor.encode_items_and_users(ratings)
    
    # è¯†åˆ«é•¿å°¾ç”¨æˆ·
    print("\nğŸ¯ è¯†åˆ«é•¿å°¾ç”¨æˆ·...")
    long_tail_data = processor.identify_long_tail_users(ratings, threshold=3)
    
    # åˆ›å»ºé¢„è®­ç»ƒæ•°æ®
    print("\nğŸ“¦ åˆ›å»ºé¢„è®­ç»ƒæ•°æ®...")
    pretrain_data = processor.create_pretrain_data(ratings, sample_frac=0.2)
    
    # ç”Ÿæˆåºåˆ—
    print("\nğŸ”„ ç”Ÿæˆè®­ç»ƒåºåˆ—...")
    pretrain_sequences = processor.create_sequences(pretrain_data)
    finetune_sequences = processor.create_sequences(long_tail_data)
    
    return processor, pretrain_sequences, finetune_sequences

def demo_model_architecture():
    """æ¼”ç¤ºæ¨¡å‹æ¶æ„"""
    print("\n" + "="*50)
    print("ğŸ¤– æ¨¡å‹æ¶æ„æ¼”ç¤º")
    print("="*50)
    
    # åˆ›å»ºå°å‹æ¨¡å‹ç”¨äºæ¼”ç¤º
    model = GPSDRecommender(
        n_items=500,
        d_model=128,
        n_heads=4,
        n_layers=3,
        d_ff=256,
        max_seq_len=20,
        dropout=0.1
    )
    
    print(f"ğŸ—ï¸ æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    batch_size = 8
    seq_len = 15
    
    input_ids = torch.randint(1, 501, (batch_size, seq_len))
    attention_mask = torch.ones(batch_size, seq_len)
    
    print(f"ğŸ“¥ è¾“å…¥å½¢çŠ¶: {input_ids.shape}")
    
    with torch.no_grad():
        logits = model(input_ids, attention_mask)
    
    print(f"ğŸ“¤ è¾“å‡ºå½¢çŠ¶: {logits.shape}")
    print(f"âœ“ å‰å‘ä¼ æ’­æˆåŠŸ")
    
    # æ¼”ç¤ºå†»ç»“å‚æ•°
    print("\nğŸ”’ æ¼”ç¤ºå‚æ•°å†»ç»“:")
    print(f"é¢„è®­ç»ƒæ¨¡å¼å‚æ•°: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")
    
    model.finetune_mode()
    print(f"å¾®è°ƒæ¨¡å¼å‚æ•°: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")
    
    return model

def demo_training(processor, pretrain_sequences, finetune_sequences, model):
    """æ¼”ç¤ºè®­ç»ƒè¿‡ç¨‹"""
    print("\n" + "="*50)
    print("ğŸ”¥ è®­ç»ƒè¿‡ç¨‹æ¼”ç¤º")
    print("="*50)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print("\nğŸ”§ åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
    pretrain_train_loader, pretrain_val_loader = create_dataloaders(
        pretrain_sequences[:200], batch_size=16, max_seq_len=20  # ä½¿ç”¨å°‘é‡æ•°æ®æ¼”ç¤º
    )
    
    finetune_train_loader, finetune_val_loader = create_dataloaders(
        finetune_sequences[:100], batch_size=16, max_seq_len=20
    )
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = RecommenderTrainer(model, device, learning_rate=1e-3)
    
    # å¿«é€Ÿé¢„è®­ç»ƒæ¼”ç¤º
    print("\nâš¡ å¿«é€Ÿé¢„è®­ç»ƒæ¼”ç¤º (1 epoch)...")
    start_time = time.time()
    
    pretrain_history = trainer.pretrain(
        pretrain_train_loader,
        pretrain_val_loader,
        epochs=1,
        save_path="./demo_pretrained.pth"
    )
    
    pretrain_time = time.time() - start_time
    print(f"âœ“ é¢„è®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {pretrain_time:.2f}ç§’")
    
    # å¿«é€Ÿå¾®è°ƒæ¼”ç¤º
    print("\nğŸ¯ å¿«é€Ÿå¾®è°ƒæ¼”ç¤º (1 epoch)...")
    start_time = time.time()
    
    finetune_history = trainer.finetune(
        finetune_train_loader,
        finetune_val_loader,
        epochs=1,
        save_path="./demo_finetuned.pth",
        early_stopping_patience=1
    )
    
    finetune_time = time.time() - start_time
    print(f"âœ“ å¾®è°ƒå®Œæˆï¼Œè€—æ—¶: {finetune_time:.2f}ç§’")
    
    return trainer

def demo_evaluation(trainer, finetune_sequences):
    """æ¼”ç¤ºè¯„ä¼°è¿‡ç¨‹"""
    print("\n" + "="*50)
    print("ğŸ“ˆ è¯„ä¼°è¿‡ç¨‹æ¼”ç¤º")
    print("="*50)
    
    # åˆ›å»ºè¯„ä¼°å™¨
    evaluator = RecommendationEvaluator(trainer.model, trainer.device)
    
    # ä½¿ç”¨å°‘é‡æµ‹è¯•æ•°æ®
    test_sequences = finetune_sequences[-50:]  # ä½¿ç”¨æœ€å50ä¸ªåºåˆ—ä½œä¸ºæµ‹è¯•
    
    print(f"ğŸ§ª æµ‹è¯•åºåˆ—æ•°é‡: {len(test_sequences)}")
    
    # è¯„ä¼°æ¨¡å‹
    print("\nğŸ” å¼€å§‹è¯„ä¼°...")
    start_time = time.time()
    
    results = evaluator.evaluate_model(
        test_sequences,
        k_values=[5, 10],
        batch_size=16
    )
    
    evaluation_time = time.time() - start_time
    print(f"âœ“ è¯„ä¼°å®Œæˆï¼Œè€—æ—¶: {evaluation_time:.2f}ç§’")
    
    # A/Bæµ‹è¯•æ¨¡æ‹Ÿ
    print("\nğŸ’° A/Bæµ‹è¯•æ¨¡æ‹Ÿ...")
    ab_test_results = evaluator.simulate_ab_test(
        test_sequences,
        baseline_gmv=100000.0,  # 10ä¸‡åŸºå‡†GMV
        expected_improvement=7.97
    )
    
    # æ‰“å°ç»“æœ
    print_evaluation_report(results, ab_test_results)
    
    return results, ab_test_results

def demo_recommendation_example(trainer, processor):
    """æ¼”ç¤ºæ¨èç¤ºä¾‹"""
    print("\n" + "="*50)
    print("ğŸ¯ æ¨èç¤ºä¾‹æ¼”ç¤º")
    print("="*50)
    
    # åˆ›å»ºç¤ºä¾‹ç”¨æˆ·åºåˆ—
    example_sequence = [1, 15, 23, 45, 67]  # ç¤ºä¾‹ç‰©å“åºåˆ—
    
    print(f"ğŸ‘¤ ç”¨æˆ·å†å²äº¤äº’: {example_sequence}")
    
    # å‡†å¤‡è¾“å…¥
    input_ids = torch.tensor([example_sequence + [0] * (20 - len(example_sequence))]).long()
    attention_mask = torch.tensor([[1] * len(example_sequence) + [0] * (20 - len(example_sequence))]).long()
    
    # ç”Ÿæˆæ¨è
    trainer.model.eval()
    with torch.no_grad():
        logits = trainer.model(input_ids.to(trainer.device), attention_mask.to(trainer.device))
        
        # æ’é™¤å·²äº¤äº’ç‰©å“
        for item in example_sequence:
            logits[0, item] = float('-inf')
        
        # è·å–Top-10æ¨è
        _, top_items = torch.topk(logits[0], 10)
        recommendations = top_items.cpu().numpy().tolist()
    
    print(f"ğŸ¬ Top-10 æ¨èç‰©å“: {recommendations}")
    
    # è®¡ç®—æ¨èåˆ†æ•°
    scores = torch.softmax(logits[0], dim=0)
    rec_scores = [scores[item].item() for item in recommendations]
    
    print("\nğŸ“Š æ¨èè¯¦æƒ…:")
    for i, (item, score) in enumerate(zip(recommendations, rec_scores), 1):
        print(f"  {i:2d}. ç‰©å“ {item:3d} - åˆ†æ•°: {score:.4f}")

def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸš€ åŸºäºTransformerçš„å†·å¯åŠ¨æ¨èç³»ç»Ÿ - å¿«é€Ÿæ¼”ç¤º")
    print("" + "="*60)
    
    try:
        # 1. æ•°æ®é¢„å¤„ç†æ¼”ç¤º
        processor, pretrain_sequences, finetune_sequences = demo_data_preprocessing()
        
        # 2. æ¨¡å‹æ¶æ„æ¼”ç¤º
        model = demo_model_architecture()
        
        # 3. è®­ç»ƒæ¼”ç¤º
        trainer = demo_training(processor, pretrain_sequences, finetune_sequences, model)
        
        # 4. è¯„ä¼°æ¼”ç¤º
        results, ab_results = demo_evaluation(trainer, finetune_sequences)
        
        # 5. æ¨èç¤ºä¾‹
        demo_recommendation_example(trainer, processor)
        
        print("\n" + "="*60)
        print("ğŸ‰ æ¼”ç¤ºå®Œæˆï¼")
        print("\nğŸ’¡ æç¤º:")
        print("  - è¿è¡Œ 'python main.py --mode full' è¿›è¡Œå®Œæ•´è®­ç»ƒ")
        print("  - æŸ¥çœ‹ README.md äº†è§£è¯¦ç»†ä½¿ç”¨æ–¹æ³•")
        print("  - è°ƒæ•´å‚æ•°ä»¥é€‚åº”æ‚¨çš„æ•°æ®é›†")
        
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print("\nğŸ”§ æ•…éšœæ’é™¤å»ºè®®:")
        print("  1. æ£€æŸ¥ä¾èµ–åŒ…æ˜¯å¦æ­£ç¡®å®‰è£…")
        print("  2. ç¡®è®¤Pythonç‰ˆæœ¬ >= 3.7")
        print("  3. å¦‚æœå†…å­˜ä¸è¶³ï¼Œå¯ä»¥å‡å°‘æ•°æ®é‡")
        raise

if __name__ == "__main__":
    main()