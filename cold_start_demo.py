#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å†·å¯åŠ¨ç”¨æˆ·æ¨èæ¼”ç¤ºè„šæœ¬
å±•ç¤ºå¦‚ä½•ä¸ºæ–°ç”¨æˆ·æˆ–äº¤äº’å†å²å¾ˆå°‘çš„ç”¨æˆ·ç”Ÿæˆæ¨è

ä½¿ç”¨æ–¹æ³•:
python cold_start_demo.py
"""

import torch
import numpy as np
import pandas as pd
import pickle
import os
from typing import List, Dict, Tuple

from model import GPSDRecommender
from data_preprocessing import MovieLensDataProcessor

class ColdStartRecommender:
    """å†·å¯åŠ¨æ¨èå™¨"""
    
    def __init__(self, model_path: str, models_dir: str = './models/'):
        """
        åˆå§‹åŒ–å†·å¯åŠ¨æ¨èå™¨
        
        Args:
            model_path: è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„
            models_dir: æ¨¡å‹æ–‡ä»¶å¤¹è·¯å¾„
        """
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.models_dir = models_dir
        
        # åŠ è½½æ¨¡å‹é…ç½®
        self._load_metadata()
        
        # åˆ›å»ºå¹¶åŠ è½½æ¨¡å‹
        self.model = GPSDRecommender(
            n_items=self.n_items,
            d_model=self.model_config.get('d_model', 384),
            n_heads=self.model_config.get('n_heads', 12),
            n_layers=self.model_config.get('n_layers', 8),
            d_ff=self.model_config.get('d_ff', 1536),
            max_seq_len=self.model_config.get('max_seq_len', 80),
            dropout=self.model_config.get('dropout', 0.1)
        )
        
        self.model.load_pretrained(model_path)
        self.model.to(self.device)
        self.model.eval()
        
        # åŠ è½½ç¼–ç å™¨
        self._load_encoders()
        
        print(f"âœ“ å†·å¯åŠ¨æ¨èå™¨å·²åˆå§‹åŒ–")
        print(f"âœ“ è®¾å¤‡: {self.device}")
        print(f"âœ“ ç‰©å“æ•°é‡: {self.n_items}")
    
    def _load_metadata(self):
        """åŠ è½½æ¨¡å‹å…ƒæ•°æ®"""
        metadata_path = os.path.join(self.models_dir, 'metadata.pkl')
        if os.path.exists(metadata_path):
            with open(metadata_path, 'rb') as f:
                metadata = pickle.load(f)
                self.n_items = metadata['n_items']
                self.n_users = metadata['n_users']
                self.model_config = metadata.get('model_config', {})
        else:
            # é»˜è®¤é…ç½®
            self.n_items = 3952
            self.n_users = 6040
            self.model_config = {
                'd_model': 384,
                'n_heads': 12,
                'n_layers': 8,
                'd_ff': 1536,
                'max_seq_len': 80,
                'dropout': 0.1
            }
    
    def _load_encoders(self):
        """åŠ è½½ç”¨æˆ·å’Œç‰©å“ç¼–ç å™¨"""
        # åŠ è½½ç‰©å“ç¼–ç å™¨
        item_encoder_path = os.path.join(self.models_dir, 'item_encoder.pkl')
        if os.path.exists(item_encoder_path):
            with open(item_encoder_path, 'rb') as f:
                self.item_encoder = pickle.load(f)
        else:
            self.item_encoder = None
            
        # åŠ è½½ç”¨æˆ·ç¼–ç å™¨
        user_encoder_path = os.path.join(self.models_dir, 'user_encoder.pkl')
        if os.path.exists(user_encoder_path):
            with open(user_encoder_path, 'rb') as f:
                self.user_encoder = pickle.load(f)
        else:
            self.user_encoder = None
    
    def recommend_for_new_user(self, 
                              user_preferences: List[int] = None,
                              k: int = 10,
                              strategy: str = 'popular') -> List[int]:
        """
        ä¸ºå…¨æ–°ç”¨æˆ·ç”Ÿæˆæ¨è
        
        Args:
            user_preferences: ç”¨æˆ·åå¥½ç‰©å“åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
            k: æ¨èç‰©å“æ•°é‡
            strategy: æ¨èç­–ç•¥ ('popular', 'random', 'model')
            
        Returns:
            æ¨èç‰©å“IDåˆ—è¡¨
        """
        if strategy == 'popular':
            # åŸºäºæµè¡Œåº¦çš„æ¨è
            return self._recommend_popular_items(k)
        elif strategy == 'random':
            # éšæœºæ¨è
            return self._recommend_random_items(k)
        elif strategy == 'model' and user_preferences:
            # åŸºäºæ¨¡å‹çš„æ¨è
            return self._recommend_with_model(user_preferences, k)
        else:
            # é»˜è®¤ä½¿ç”¨æµè¡Œåº¦æ¨è
            return self._recommend_popular_items(k)
    
    def recommend_for_cold_user(self, 
                               user_history: List[int],
                               k: int = 10) -> List[int]:
        """
        ä¸ºå†·å¯åŠ¨ç”¨æˆ·ï¼ˆæœ‰å°‘é‡å†å²äº¤äº’ï¼‰ç”Ÿæˆæ¨è
        
        Args:
            user_history: ç”¨æˆ·å†å²äº¤äº’ç‰©å“åˆ—è¡¨
            k: æ¨èç‰©å“æ•°é‡
            
        Returns:
            æ¨èç‰©å“IDåˆ—è¡¨
        """
        return self._recommend_with_model(user_history, k)
    
    def _recommend_with_model(self, 
                             user_sequence: List[int],
                             k: int = 10) -> List[int]:
        """ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ç”Ÿæˆæ¨è"""
        max_seq_len = self.model.backbone.max_seq_len
        
        # å‡†å¤‡è¾“å…¥åºåˆ—
        if len(user_sequence) > max_seq_len:
            # å¦‚æœåºåˆ—å¤ªé•¿ï¼Œå–æœ€åmax_seq_lenä¸ªç‰©å“
            input_sequence = user_sequence[-max_seq_len:]
        else:
            # å¦‚æœåºåˆ—å¤ªçŸ­ï¼Œè¿›è¡Œpadding
            input_sequence = user_sequence + [0] * (max_seq_len - len(user_sequence))
        
        # åˆ›å»ºattention mask
        attention_mask = [1 if item != 0 else 0 for item in input_sequence]
        
        # è½¬æ¢ä¸ºtensor
        input_ids = torch.tensor([input_sequence], dtype=torch.long).to(self.device)
        attention_mask = torch.tensor([attention_mask], dtype=torch.long).to(self.device)
        
        # ç”Ÿæˆæ¨è
        with torch.no_grad():
            logits = self.model(input_ids, attention_mask)
            
            # æ’é™¤å·²äº¤äº’ç‰©å“
            for item in user_sequence:
                if 1 <= item <= self.n_items:
                    logits[0, item] = float('-inf')
            
            # è·å–Top-Kæ¨è
            _, top_items = torch.topk(logits[0], k)
            recommendations = top_items.cpu().numpy().tolist()
        
        return recommendations
    
    def _recommend_popular_items(self, k: int = 10) -> List[int]:
        """æ¨èçƒ­é—¨ç‰©å“ï¼ˆç®€å•å®ç°ï¼‰"""
        # è¿™é‡Œç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥åŸºäºç‰©å“æµè¡Œåº¦ç»Ÿè®¡
        popular_items = list(range(1, min(k + 1, self.n_items + 1)))
        return popular_items
    
    def _recommend_random_items(self, k: int = 10) -> List[int]:
        """éšæœºæ¨èç‰©å“"""
        return np.random.choice(range(1, self.n_items + 1), k, replace=False).tolist()
    
    def get_recommendation_scores(self, 
                                 user_sequence: List[int],
                                 candidate_items: List[int] = None) -> Dict[int, float]:
        """
        è·å–æ¨èåˆ†æ•°
        
        Args:
            user_sequence: ç”¨æˆ·å†å²åºåˆ—
            candidate_items: å€™é€‰ç‰©å“åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            ç‰©å“IDåˆ°æ¨èåˆ†æ•°çš„æ˜ å°„
        """
        max_seq_len = self.model.backbone.max_seq_len
        
        # å‡†å¤‡è¾“å…¥
        if len(user_sequence) > max_seq_len:
            input_sequence = user_sequence[-max_seq_len:]
        else:
            input_sequence = user_sequence + [0] * (max_seq_len - len(user_sequence))
        
        attention_mask = [1 if item != 0 else 0 for item in input_sequence]
        
        input_ids = torch.tensor([input_sequence], dtype=torch.long).to(self.device)
        attention_mask = torch.tensor([attention_mask], dtype=torch.long).to(self.device)
        
        with torch.no_grad():
            logits = self.model(input_ids, attention_mask)
            scores = torch.softmax(logits[0], dim=0)
        
        # è¿”å›æŒ‡å®šç‰©å“çš„åˆ†æ•°
        if candidate_items:
            return {item: scores[item].item() for item in candidate_items if 1 <= item <= self.n_items}
        else:
            return {item: scores[item].item() for item in range(1, self.n_items + 1)}

def demo_cold_start_scenarios():
    """æ¼”ç¤ºä¸åŒçš„å†·å¯åŠ¨åœºæ™¯"""
    print("ğŸš€ å†·å¯åŠ¨æ¨èæ¼”ç¤º")
    print("=" * 50)
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    model_path = './models/finetuned_model.pth'
    if not os.path.exists(model_path):
        model_path = './models/pretrained_model.pth'
    
    if not os.path.exists(model_path):
        print("âŒ æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œè¯·å…ˆè¿è¡Œè®­ç»ƒ")
        print("   è¿è¡Œ: python main.py --mode full")
        return
    
    # åˆå§‹åŒ–æ¨èå™¨
    recommender = ColdStartRecommender(model_path)
    
    print("\nğŸ“‹ å†·å¯åŠ¨æ¨èåœºæ™¯æ¼”ç¤º")
    print("-" * 30)
    
    # åœºæ™¯1ï¼šå…¨æ–°ç”¨æˆ·ï¼ˆæ— ä»»ä½•å†å²ï¼‰
    print("\nğŸ†• åœºæ™¯1ï¼šå…¨æ–°ç”¨æˆ·æ¨è")
    new_user_recs = recommender.recommend_for_new_user(k=10, strategy='popular')
    print(f"æ¨èç‰©å“: {new_user_recs}")
    
    # åœºæ™¯2ï¼šæœ‰å°‘é‡åå¥½çš„æ–°ç”¨æˆ·
    print("\nğŸ‘¤ åœºæ™¯2ï¼šæœ‰åå¥½çš„æ–°ç”¨æˆ·")
    user_preferences = [1, 15, 23]  # ç”¨æˆ·è¡¨ç¤ºå–œæ¬¢è¿™äº›ç‰©å“
    pref_recs = recommender.recommend_for_new_user(
        user_preferences=user_preferences, 
        k=10, 
        strategy='model'
    )
    print(f"ç”¨æˆ·åå¥½: {user_preferences}")
    print(f"æ¨èç‰©å“: {pref_recs}")
    
    # åœºæ™¯3ï¼šå†·å¯åŠ¨ç”¨æˆ·ï¼ˆæœ‰1-4æ¬¡äº¤äº’ï¼‰
    print("\nâ„ï¸ åœºæ™¯3ï¼šå†·å¯åŠ¨ç”¨æˆ·ï¼ˆå°‘é‡å†å²ï¼‰")
    cold_user_history = [5, 12, 28, 45]  # ç”¨æˆ·å†å²äº¤äº’
    cold_recs = recommender.recommend_for_cold_user(cold_user_history, k=10)
    print(f"ç”¨æˆ·å†å²: {cold_user_history}")
    print(f"æ¨èç‰©å“: {cold_recs}")
    
    # åœºæ™¯4ï¼šè·å–æ¨èåˆ†æ•°
    print("\nğŸ“Š åœºæ™¯4ï¼šæ¨èåˆ†æ•°åˆ†æ")
    candidate_items = [1, 10, 20, 30, 40, 50]
    scores = recommender.get_recommendation_scores(
        cold_user_history, 
        candidate_items
    )
    print(f"å€™é€‰ç‰©å“æ¨èåˆ†æ•°:")
    for item, score in sorted(scores.items(), key=lambda x: x[1], reverse=True):
        print(f"  ç‰©å“ {item:2d}: {score:.6f}")
    
    print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
    print("  1. æ–°ç”¨æˆ·ï¼šä½¿ç”¨æµè¡Œåº¦æ¨èæˆ–åŸºäºæ³¨å†Œä¿¡æ¯çš„æ¨è")
    print("  2. æœ‰åå¥½æ–°ç”¨æˆ·ï¼šç»“åˆåå¥½ä¿¡æ¯ä½¿ç”¨æ¨¡å‹æ¨è")
    print("  3. å†·å¯åŠ¨ç”¨æˆ·ï¼šå……åˆ†åˆ©ç”¨æœ‰é™çš„å†å²äº¤äº’")
    print("  4. æŒç»­å­¦ä¹ ï¼šéšç€ç”¨æˆ·äº¤äº’å¢åŠ ï¼Œæ¨èä¼šè¶Šæ¥è¶Šå‡†ç¡®")

def create_recommendation_api_example():
    """åˆ›å»ºæ¨èAPIä½¿ç”¨ç¤ºä¾‹"""
    print("\nğŸ”§ æ¨èAPIä½¿ç”¨ç¤ºä¾‹")
    print("-" * 30)
    
    code_example = '''
# æ¨èAPIä½¿ç”¨ç¤ºä¾‹
from cold_start_demo import ColdStartRecommender

# åˆå§‹åŒ–æ¨èå™¨
recommender = ColdStartRecommender('./models/finetuned_model.pth')

# ä¸ºæ–°ç”¨æˆ·æ¨è
def recommend_for_new_user(user_id):
    """ä¸ºæ–°ç”¨æˆ·æ¨è"""
    recommendations = recommender.recommend_for_new_user(
        k=10, 
        strategy='popular'
    )
    return recommendations

# ä¸ºå†·å¯åŠ¨ç”¨æˆ·æ¨è
def recommend_for_cold_user(user_id, user_history):
    """ä¸ºå†·å¯åŠ¨ç”¨æˆ·æ¨è"""
    recommendations = recommender.recommend_for_cold_user(
        user_history=user_history,
        k=10
    )
    return recommendations

# è·å–æ¨èåˆ†æ•°
def get_item_scores(user_history, candidate_items):
    """è·å–ç‰©å“æ¨èåˆ†æ•°"""
    scores = recommender.get_recommendation_scores(
        user_sequence=user_history,
        candidate_items=candidate_items
    )
    return scores
'''
    
    print(code_example)

if __name__ == "__main__":
    try:
        demo_cold_start_scenarios()
        create_recommendation_api_example()
        print("\nğŸ‰ å†·å¯åŠ¨æ¨èæ¼”ç¤ºå®Œæˆï¼")
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print("\nğŸ”§ æ•…éšœæ’é™¤å»ºè®®:")
        print("  1. ç¡®ä¿å·²å®Œæˆæ¨¡å‹è®­ç»ƒ")
        print("  2. æ£€æŸ¥æ¨¡å‹æ–‡ä»¶è·¯å¾„")
        print("  3. ç¡®è®¤ä¾èµ–åŒ…æ­£ç¡®å®‰è£…")
        raise